[["index.html", "Data Visualization Chapter 1 Welcome 1.1 What is Data Visualization? 1.2 What is the purpose of data visualization? 1.3 Course Goals", " Data Visualization Andrew Irwin 2020-12-28 Chapter 1 Welcome Data visualization is a critical skill for anyone interested in using data to think and persuade. This course focusses on three aspects of data visualization: What makes a good data visualization? Designing, improving, and communicating with visualizations, and the technical computer skills needed to create visualizations. 1.1 What is Data Visualization? Data visualization is the practice of turning data into graphics, which can be more easily interpreted than the raw data while remaining faithful to the original data and not misleading the intended audience. Almost every data visualization is a simplification and approximation of a raw dataset, and thus involves a perspective–the goals and biases of the person producing the visualization. Data visualization approaches vary. For some purposes, highly customized graphic design and visual style are paramount. That’s not our focus. We emphasize standardized graphical presentations – which span a wide variety of visualizations – that minimize the use of graphical elements not directly linked to the data. 1.2 What is the purpose of data visualization? Data visualization is a set of tools for telling stories with data. The usual goal is to communicate an interpretation of a dataset to a particular audience, to make an argument you have worked out from an analysis of the data. The visualization is a device to help you do that. Visualizations are best when accompanied by written explanations (despite the claim that a picture is worth a thousand words). Once the message is understood and internalized, a good visualization will tell the story “by itself”. 1.3 Course Goals By the end of the course you will be familiar with several aspects of data visualzation. Visual impact and aesthetic aspects of graphics Understand the relationship between the structure of your data and the perceptual features of your graphics. Describe aesthetic aspects of good plots. Use length, shape, size, colour, annotations, and other features to effectively display data and enable comparitive visual interpretation. Visualization as communication Visualization is a visual language for communication, which should be accompanied by written interpretations Communication effectiveness should be evaluated by peer-review and critical, constructive feedback Visualizations should be developed through an iterative process akin to editing text, including the process of refining plots to highlight key features of the data, labeling items of interest, annotating plots, and changing overall appearance Visualizations can be presented in different formats for different of audiences and different communications goals Computing skills Learn the basics of using R, Rstudio, several R add-on packages, and git Read data in several different formats into R Create graphs with ggplot2 for continuous and categorical variables with informative legends. Add error bars, linear models, smooths, labels, and other annotations to a graph Create small-multiple (facetted) plots. Use the principles of tidy data tables to facilitate transformation and analysis of data. Reshape data to make it tidy. Summarize and transform data using dplyr Reshape data using pivots Create maps and some alternatives for presenting spatial data. Write reproducible documents with R markdown to document your analysis process and present your results Distribute data, code, and results using git and github Access and interpret help resources (built-in help, vignettes, web pages, online discussion forums, blogs). Develop skills for independently learning new data visualization methods and software Statistical models Use a variety of modeling techniques such as LOESS, OLS, robust regression, polynomial regression, and quantile regression Learn how to extract model information to compare different statistical models Use principal component analysis (PCA) to reduce the dimensionality of complex datasets, increasing interpretability while minimizing information loss Use multidimensional scaling (MDS) to visualize and compare similarities and dissimilarities between variables Divide observations into homogeneous and distinct groups using K-means "],["syllabus.html", "Chapter 2 Syllabus 2.1 Course Description 2.2 Course Prerequisites 2.3 Course materials 2.4 Course structure 2.5 Evaluation 2.6 Software 2.7 Letter grades 2.8 Course Policies 2.9 University Policies and Statements 2.10 Student Resources and Support", " Chapter 2 Syllabus This is the syllabus for the Data Visualization (STAT 2430) course in Winter 2021 at Dalhousie University. 2.1 Course Description Data visualization is the art and science of turning data into readable graphics. We will explore how to design and create data visualizations. This exploration will include both the principles and techniques of data visualization. Students will learn the value of visualization, specific techniques and understand how to select the best visualization method. 2.2 Course Prerequisites At least one MATH or STAT course at or above the 1000 level. No experience with R or computer programming is required, but a desire to learn about both is essential. 2.3 Course materials Course notes: Andrew J Irwin (2021) Data visualization Will be revised throughout the course. Textbook: Kieran Healy (2018) Data Visualization: A Practical Introduction. Princeton University Press. Supplemental textbooks: Garret Grolemund &amp; Hadley Wickham (2017) R for data science. O’Reilly. Claus O. Wilke (2019) Fundamentals of data visualization. O’Reilly. The textbook and supplemental textbooks are available in printed form and online. The online versions are free to use. You are not required to buy the books on paper. All three are excellent books with very distinct goals. 2.4 Course structure Each week will be structured around the following components: Recorded mini-lectures for each lesson (linked to course notes and slides) Reading course notes and excerpts from the textbooks linked to each lesson Interactive discussion of the week’s lessons (Tuesday, 8:30 am Atlantic) Live coding tutorial / lab (linked to materials created before and during the meeting, Thursday 8:30 am Atlantic) Opportunities to develop and demonstrate your knowledge (tasks, assignments, and a term project) Follow the detailed outline for each week’s plan to keep you on track. If you have questions about the course material, please ask them during the Tuesday synchronous meetings. If your question can’t wait, write it on the Piazza discussion forum. If you have questions specific to your situation that should not be shared with the class, please send me an email. Please only use email for communication that should be private, as general questions are best asked in public or on the discussion forum where everyone in the class can benefit from the exchange. Please feel free to use the discussion forum to talk with other classmates and help each other. We will use Collaborate Ultra accessed through Brightspace for the interactive sessions. Generally these will be recorded so that you can watch them later if you are unable to participate. You are strongly encouraged to come to these meetings. The interactive sessions are the primary forum for asking questions and discussing course material. These regular meetings will help give your work on the course structure. I strongly encourage you to “raise your hand” during the discussion and ask questions using your voice. Some students prefer to use the chat to ask questions, and that is fine with me, but from my perspective it leads to a more disjointed and less useful interaction. 2.5 Evaluation Tasks are opportunities to test your understanding of the key concepts from each lesson and demonstrate you have developed basic profiency with some computing skills. Most lessons will have a task for you to complete. Assignments combine skills from multiple lessons into a meaningful data visualization activity. These will require using skills from multiple tasks and applying the content of lessons in thoughtful and sometimes creative ways. The final project is an opportunity to combine many of the skills learned in the course. You will explore, analyze, and present to a reader an analysis of a dataset of your choice. The proposal will select a dataset and describe some of your planned analyses. The oral presentation will be a 5 minute overview of your data and a couple of key visualizations. The report will be a polished document showing off many of the ideas of the course using this dataset. Tasks for most lessons (30%, roughly 2 per week, equally weighted) Assignments (40%, roughly 1 every two weeks, equally weighted) Term project, divided into three components Proposal, due Friday 5 March, 5% Oral presentation, due Thursday 1 April, 10% Report, due Friday 9 April, 15% Tasks are due on Wednesdays. Assignments are due on Monday mornings. Late work will be accepted without penalty until the work is graded or solutions are posted. After that, no later work will be accepted, but your two lowest (or missing) task marks will be dropped from your evaluation. If an additional accommodation is requested and granted, the value of that work will be redistributed to other tasks or assignments. If you anticipate not being able to submit the proposal, oral presentation, or report on time, please contact me by email. Grades will be reported on Brightspace 2.6 Software The statistical software R and RStudio and version control software git will be used in this course. No prior experience with R, RStudio or git is assumed. We’ll take class time to learn the software. To download and install R go to r-project.org and click on the link to download R To download and install Rstudio, go to Rstudio.com and click on the link to download Rstudio To download and install git: on Windows, go to git-scm.org and click on the link to download a version for Windows on Macintosh, use the Terminal app and type ‘xcode-select –install’ to download and install git. These tools can be installed on Linux computers as well. Contact me if you have trouble. If you have a Chromebook you can use all these tools through the cloud service rstudio.cloud. Everyone should learn to use the cloud service as a backup in case of problems with setting up the software on their own computer. R and Rstudio are available on Dalhousie computer labs, but the git version control software must be installed following the instructions for Windows computers above. Since all your user files are erased from lab computers when you log out, this process must be repeated on each login. Videos demonstrating how to install this software are on Brightspace. 2.7 Letter grades Your numerical grade will be converted to a letter grade for the course using the Dalhousie Common Grade Scale. First your numerical grade will be rounded up to the nearest integer, then it will be converted to a letter using this table. html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #glokulzzwy .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #glokulzzwy .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #glokulzzwy .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #glokulzzwy .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #glokulzzwy .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #glokulzzwy .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #glokulzzwy .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #glokulzzwy .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #glokulzzwy .gt_column_spanner_outer:first-child { padding-left: 0; } #glokulzzwy .gt_column_spanner_outer:last-child { padding-right: 0; } #glokulzzwy .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #glokulzzwy .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #glokulzzwy .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #glokulzzwy .gt_from_md > :first-child { margin-top: 0; } #glokulzzwy .gt_from_md > :last-child { margin-bottom: 0; } #glokulzzwy .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #glokulzzwy .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #glokulzzwy .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #glokulzzwy .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #glokulzzwy .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #glokulzzwy .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #glokulzzwy .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #glokulzzwy .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #glokulzzwy .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #glokulzzwy .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #glokulzzwy .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #glokulzzwy .gt_sourcenote { font-size: 90%; padding: 4px; } #glokulzzwy .gt_left { text-align: left; } #glokulzzwy .gt_center { text-align: center; } #glokulzzwy .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #glokulzzwy .gt_font_normal { font-weight: normal; } #glokulzzwy .gt_font_bold { font-weight: bold; } #glokulzzwy .gt_font_italic { font-style: italic; } #glokulzzwy .gt_super { font-size: 65%; } #glokulzzwy .gt_footnote_marks { font-style: italic; font-size: 65%; } Letter grade Grade range A+ 90-100 A 85-89 A- 80-84 B+ 77-79 B 73-76 B- 70-72 C+ 65-69 C 60-64 C- 55-59 D 50-54 F 0-49 2.8 Course Policies Credit will not be given for assignments submitted after grading is complete or the solutions are posted. If you miss an assignment due to illness or other event outside your control, contact me for an accommodation. If an accomodation is granted, assignment weight will be shifted to the rest of the assignments. Your two lowest Task grades will be dropped from the calculation of your final grade automatically and as a result I will be reluctant to offer accommodation for late or missed tasks. Your goal in this course is to learn the principles and skills of data visualization. Most people benefit from a mixture of collaborative and independent work. The general guideline is that work you submit should be your own—your ideas, your thoughts, your choices, your code, your typing. You are encouraged to discuss your work with the instructor and students. If you help another student, be careful you don’t help them so much that you inhibit their learning. Tasks are primarily designed to help you learn and you are encouraged to seek assistance from classmates, but work you submit must be your own. Assignments are assessments of your skills and should be done independently. The final project and its components may be done in groups, but the work on the project should only be the work of members of the group. Copying work from any other sources is not allowed and will be considered an academic offense for this course. You are encouraged to learn from many different sources; if you make use of material outside of course materials on assignments or the project report, include references to the material and a description of what you used in a “Sources used” section at the end of your work. 2.9 University Policies and Statements This course is governed by the academic rules and regulations set forth in the University Calendar and by Senate Missed or Late Academic Requirements due to Student Absence. As per Senate decision instructors may not require medical notes of students who must miss an academic requirement, including the final exam, for courses offered during fall or winter 2020-21 (until April 30, 2021). Information on regular policy, including the use of the Student Declaration of Absence can be found here. Academic Integrity. At Dalhousie University, we are guided in all of our work by the values of academic integrity: honesty, trust, fairness, responsibility and respect (The Center for Academic Integrity, Duke University, 1999). As a student, you are required to demonstrate these values in all of the work you do. The University provides policies and procedures that every member of the university community is required to follow to ensure academic integrity. More information. Accessibility. The Advising and Access Services Centre is Dalhousie’s centre of expertise for student accessibility and accommodation. The advising team works with students who request accommodation as a result of a disability, religious obligation, or any barrier related to any other characteristic protected under Human Rights legislation (Canada and Nova Scotia). More information. Student Code of Conduct. Everyone at Dalhousie is expected to treat others with dignity and respect. The Code of Student Conduct allows Dalhousie to take disciplinary action if students don’t follow this community expectation. When appropriate, violations of the code can be resolved in a reasonable and informal manner—perhaps through a restorative justice process. If an informal resolution can’t be reached, or would be inappropriate, procedures exist for formal dispute resolution. Code. Diversity and Inclusion - Culture of Respect. Every person at Dalhousie has a right to be respected and safe. We believe inclusiveness is fundamental to education. We stand for equality. Dalhousie is strengthened in our diversity. We are a respectful and inclusive community. We are committed to being a place where everyone feels welcome and supported, which is why our Strategic Direction prioritizes fostering a culture of diversity and inclusiveness. Statement. Recognition of Mi’kmaq Territory. Dalhousie University would like to acknowledge that the University is on Traditional Mi’kmaq Territory. The Elders in Residence program provides students with access to First Nations elders for guidance, counsel and support. Visit or e-mail the Indigenous Student Centre (1321 Edward St) (elders@dal.ca). Information. Important Dates in the Academic Year (including add/drop dates) University Grading Practices 2.10 Student Resources and Support Please follow the following links for additional resources and support. Advising: General Advising, Science Program Advisors, Indigenous Student Centre, Black Advising Centre, International Centre Academic supports: Library, Writing Centre, Studying for Success, Copyright Office, Fair Dealing Guidelines Other supports and services: Student Health &amp; Wellness Centre, Student Advocacy, Ombudsperson Safety: Biosafety, Chemical Safety, Radiation Safety, Scent‐Free Program "],["outline.html", "Chapter 3 Detailed outline 3.1 Important dates 3.2 Course calendar 3.3 Another run at this plan", " Chapter 3 Detailed outline Synchronous sessions will be held on Tuesday and Thursday starting at 8:35 and ending by 9:55 (or earlier.) You can find the link to these sessions on Brightspace. Most sessions will be recorded and posted on Brightspace. 3.1 Important dates Wed 6 Jan: Term begins Fri 5 Feb: Munro day, University closed 15-19 Feb: Study break Fri 12 March: Project proposal due Fri 2 Apr: Good Friday, University closed Tue 6 Apr: Last Tuesday/Thursday class Thu 8 Apr: Last day of classes Fri 9 Apr: Final project due 10-23 Apr: Exam period We have 24 synchronous sessions. The last two will be used for oral presentations. 3.2 Course calendar This is a tentative schedule which will be revised throughout the term. Each lesson has written notes, a recorded video, and slides. There is a fair amount of duplication among these materials. Some students will prefer the video, others will prefer the written notes and slides. I suggest you learn which you prefer, or if you need to watch the video and read the notes, by experimentation. The tasks are designed to be sure you know the most important parts of each lesson. 3.2.1 Week 1: Jan 6-8 The three lessons introduce the content of the course, the tools we will use, and show you how to get your computer set up for the course. Work on these elements in the following suggested order: Lesson 1: An Invitation to Data Visualization. Notes, Video, Slides. Synchronous meeting Thursday 7 January, 8:35 Atlantic on Collaborate (Brightspace) Lesson 2: The tools we will use and why: R, Rstudio, ggplot, tidyverse, markdown, git, github. Notes, Video, Slides Lesson 3: Installing R, Rstudio, packages, creating github account. Notes, Video. Task 1. Instructions. Submit on Brightspace. Task 2. Instructions. Submit on Brightspace. Tasks 1 and 2 are due Monday 11 January at 9:00 am Atlantic time. 3.2.2 Week 2: Jan 11-15 The three lessons this week discuss how we perceive visualizations, how to make your own simple scatterplot, and the how and why of using git in this course. Lesson 4: Look at data. Notes, Video, Slides Task 3. Instructions. Submit on Brightspace. Synchronous meeting Tuesday 12 January, 8:35 Atlantic on Collaborate. Lesson 5: Making your first plot. Notes, Video, Slides Lesson 6: Version control concepts and working with git. Notes. Task 4. Instructions. Nothing to submit. This is preparation for Assignment 1. Synchronous meeting Thursday 14 January, 8:35 Atlantic on Collaborate. Live coding material: R markdown, html Assignment 1. Instructions. Submit on github. Tasks 3 and 4 are due Monday 18 January at 9:00 am Atlantic time. There is nothing to submit for Task 4, but you can’t do Assignment 1 without doing it first, so please don’t delay. Assignment 1 is due Wednesday 20 January at 6:00 pm Atlantic time. 3.2.3 Week 3: Jan 18-22 Lesson 7 Introduction to the Grammar of Graphics Lesson 8 Make a plot. Healy Chapter 3 Lesson 9 Customizing plots: shape, color, lines, and more 3.2.4 Week 4: Jan 25-29 Lesson 10 Summarizing data with dplyr (group_by, filter, mutate, summarize) Lesson 11 Show the right numbers. Healy Chapter 4 Lesson 12 Graph tables, add labels, make notes. Healy Chapter 5 Lesson XX. Plot geometries. Lesson 2. Describe, summarize, and display data using tables and plots 3.2.5 Week 5: Feb 1-5 Lesson 13 Reading data (csv, tsv, xlsx); import menu item; r commands Lesson 14 Plotting small multiples (facets) Lesson 15 A bit more about R. 3.2.6 Week 6: Feb 8-12 Lesson 16 Work with models. Healy Chapter 6 Lesson 17 Linear models (lines, polynomials, robust, quantile); equationomatic Lesson 18 Loess, GAM 3.2.7 Week 7: Feb 22-26 Lesson 19 K-means Lesson 20 PCA Lesson 21 NMDS 3.2.8 Week 8: Mar 1-5 Lesson 22 Tidy data; Making data tidy (datapasta) Lesson 23 Data validation (pointblank) Lesson 24 Finding, describing data with metadata (codebook) 3.2.9 Week 9: Mar 8-12 Lesson 25 Draw maps. Healy Chapter 7 Lesson 26 Making maps and chloropleths. Heatmaps. Lesson 27 Refine your plots. Healy Chapter 8 3.2.10 Week 10: Mar 15-19 Lesson 28 Themes Lesson 29 Annotations Lesson 30 Graphics output (PDF, png, sizes, colors, themes; ragg) repurposing graphics for different media and purposes 3.2.11 Week 11: Mar 22-26 Working with factors 3.2.12 Week 12: Mar 29-April 1 Wrap up and oral presentations length slope shape color Wilke book graphs for categorical data graphs for quantitative data pivot longer and wider Working with dates 3.3 Another run at this plan Lectures Introduction to Data Visualization Reproducibility and report writing The grammar of graphics and components of a ggplot Tracking changes and sharing data and code with git A tour of plot types Aesthetic features of graphs: symbols, lines, colours, and more Organizing data Summarizing data in tables Smoothing data Making clusters from quantitive data Comparing data: overlapping points and panel plots Learning computing tools on your own (project overview) Principal component analysis and Multidimensional scaling Appendix (5 + more added during term) What is the tidyverse? Contrast with other conventions How do I know I’ve done it right? Functions and types of data in R Text data and regular expressions introduction Examples of building up figures step by step "],["evaluation-1.html", "Chapter 4 Evaluation 4.1 Tasks 4.2 Assignments 4.3 Term project", " Chapter 4 Evaluation All the work students will complete for evaluation and credit in the course is described below. 4.1 Tasks Tasks for each lesson are described here. Each task is designed to demonstrate a particular skill or idea from the lesson or prepare for the next lesson. Tasks will be evaluated on a 0-10 scale on the following rubric: 0-5: Work missing or mostly incomplete. 6-7: Mostly complete or complete with major deficiencies. 8: Complete and meets expectations. 9-10: Complete and excells in some respect: organization, clarity, creativity. 4.1.1 Task 1 (Lesson 1) Find two data visualizations that you find informative, compelling, or in need of improvement. Create a document that shows each visualization (the figure, or a snapshot of a dynamic visualization), provides the source (e.g., url and publication details if applicable). In a few sentences describe the data behind the visualization, main message conveyed by the visualization, one or two features of the visualization that make it effective or suggestions for improvement. The goal of this project isn’t to be right or wrong, but rather to start the process of looking at data visualizations through the perspective of creator, designer, and critic. It’s okay if you find visualizations from secondary sources and not the creator or original publisher. Include the reference to the source you used to find the visualiztions. Submit your work as a single PDF on Brightspace. 4.1.2 Bonus task (Lesson 2) Read Healy, Sections 2.1-2.4. There is nothing to submit for this task. 4.1.3 Task 2 (Lesson 3) See the instructions in the syllabus or in Lesson 3 notes Install R, Rstudio, and the packages identified in Healy’s Preface. Install git. Create a github account. Login to rstudio.cloud. This is a complete R, Rstudio, and git setup “in the cloud” that can be used if you have trouble using R on your own computer. Ask for help with any of these tasks if you need it. Answer the quiz on Brightspace which will ask if you were successful with each task or if you need help. Provide your github name. 4.1.4 Task 3 (Lesson 4) Some people feel very strongly about the placement of 0 on the vertical scale of plots. Look again at the carbon dioxide plots in Lesson 1. The vertical scale does not start at 0. Use the ideas in Healy Chapter 1.6 to describe how you would interpret vertical position on the carbon dioxide plots and how you could interpret this position if 0 was included on the vertical scale. Hans Rosling’s visualizations (as shown in Lesson 1) use many channels for conveying data: x and y position, color, size, an annotation for year in the plot background. The interactive versions use an animation for change over time, and mouse-over pop-ups to identify the country for each dot. These are very complex visualizations! For the plot linked above, what variables are shown for each of x and y position, color, and symbol size? According to Healy Chapter 1 which of these 4 features is most difficult to make quantitative comparisons with? Why? Do you agree? In your judgment, is this visualization effective or too complex. Watch the TED talk or experiment with the interactive version before answering the question. Write answers for these two questions in a word processor (we’ll start using R markdown soon) and submit as a single PDF on Brightspace. 4.1.5 Task 4 (Lesson 6) Use Rstudio to create a new project from a github repository. You will use this repository for Assignment 1. This is a new task, but it’s going to be a recurring task throughout the course. Here are step-by-step instructions. If you have trouble with this task, ask for help. It’s very important. Look for an invitation in your email sent earlier this week. Copy the link. Use Rstudio, menu File &gt; New Project &gt; From repository… 4.1.6 Lesson 5 Make the plot from Healy Section 2.6. Look at the other variables in the gapminder dataset and make some other plots of your choosing. Put your plots in an Rmd. Knit the R markdown file. Nothing to submit. Ask for help if you have problems. 4.1.7 Lesson 6 Check out a github repository from online course. Add a plot to the Rmd document you find there. Commit your changes and push the Rmd file back to github. More to come. 4.2 Assignments Assignments are opportunities to apply and combine the skills from several lessons. They are both structured, in that you are asked to use specific skills to accomplish a task, and creative in that you have some flexibility in the product you produce. You will be assessed on your use of technical skills and your judgement in making well-designed and effective visualizations, following the principles explored in the course. Assignments should be submitted to the relevant github repository, generally as an R markdown document. Assesment rubric: 0 none of the objectives met; document has errors that prevent knitting 1 some objectives met 2 some objectives met 3 no substantive errors 4 excellent work, clearly presented and thoughtfully designed 4.2.1 Assignment 1 Make a simple markdown document with a figure and commit to a github repository learn, describe, and use a ggplot extension. 5% (Week 7, after break) - ggrepel, cowplot, patchwork, viridislite 4.2.2 Assignment 2 learn, describe, and use a table layout package. 5% (Week 9) - DT, gt, flextable, kable/kableExtra (Do one as a 5 minute video with script and slides. Do the other as a rmd tutorial.) 4.2.3 Assignment 3 Mini-project: Tidy Tuesday 1. 5% (Week 10) 4.2.4 Assignment Mini-project: Tidy Tuesday 2. 5% (Week 11) 4.3 Term project Your final project is an analysis on a dataset of your own choosing. You can choose the data based on your interests, based on work in other courses, or independent research projects. You should demonstrate many of the techniques from the course, applying them as appropriate to develop and communicate insight into the data. You should create compelling visualizations of your data. Pay attention to your presentation: neatness, coherency, and clarity will count. All analyses must be done in RStudio using R. 4.3.1 Deliverables Proposal - due Fiday 12 March at 6:00 pm Presentation - due Friday 2 April at 6:00 pm as pre-recorded video or live presentation in class on March 30 or April 1. Report - due Friday 9 April at 6:00 pm Work in pairs. You can produce team products, or one product per team member, whichever you prefer. You have two roles in the project. First you will contribute your original creative work for the project. Second, you will act as a collaborator, providing your teammate with feedback, suggestions, debugging help, proofreading and other assistance as requested. Use a single github repository for the proposal, presentation, and final report. If you work in pairs, producing joint work, use the repository for one team member and add the other member to the repository. 4.3.2 Proposal Your main task for the proposal is to find a dataset to analyze for your project and describe at least one question you can address with data visualizations. It is important that you choose a readily accessible dataset that is large enough so multiple relationships can be explored, but no so complex that you get lost. I suggest your dataset should have at least 50 observations and about 10 variables. The variables should include categorical variables, discrete numerical variables, and continuous numerical variables. If you plan to use a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late. Do not reuse datasets from any part of the course. Here is list of data repositories containing many interesting datasets. Feel free to use data from other sources if you prefer. TidyTuesday Kaggle datasets OpenIntro datasets Awesome public datasets Bikeshare data portal Harvard Dataverse Statistics Canada Open government data: Canada, NS, and many other sources Other sources listed in the Data sources section of these notes or that you find on your own. Describe a dataset and question you can address with the data for your report. How you plan to use 5 things (overview plot, dplyr/table summary, small multiples, knn/PCA, map) Your proposal should include an Rmd document called proposal.rmd with the following sections and the proposed dataset. Introduction: The introduction should introduce your general research question and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.). Data: Place your data in the /data folder, and add dimensions and codebook to the README in that folder. Include the output of dplyr::glimpse() or skimr::skim() on your data frame. Visualization and analysis plan: The outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question. Ideas for at least two possible visualizations for exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. An idea of how at least one statistical methods described in the course (smoothing, PCA, k-means) could be useful in analyzing your data Assessment. Your proposal will be assessed for the following elements: a dataset is identifed and described (size of dataset, variables, source), a question to be investigated is clearly described, a visualization plan is presented. Scoring will be similar to exercises: 4 points (1 each) for the following 4 elements: description of data, size of data, source of data, question, 2 points for a visualization plan 2 points for presentation quality, 2 points for creativity / thoughtfulness / imagination Total 10. 4.3.3 Oral presentation The oral presentation should be about 5 minutes long. The goal is to present the highlights of your project and allow for feedback which can be incorporated as you revise your written report. You should have a small number of slides to accompany your presentation. I suggest a format such as the following: A title with your name A description of the data you are analyzing At least one question you can investigate with your data visualization At least two data visualizations A conclusion A template for a presentation (presentation.rpres) is in the project repository. Don’t show your R code; the focus should be on your results and visualzations not your computing. Set echo = FALSE to hide R code (this is already done in the template). Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found. Presentation schedule: Presentations will take place during the last workshop of the semester. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly. 4.3.4 Written report Required elements: README.rmd Data Dictionary Written report (report.rmd) presenting your visualizations and insights about your data This write-up, which you can also think of as an summary of your project, should provide information on the dataset you’re using, your research question(s), your methodology, and your findings. Repo organization The following folders and files in your project repository: presentation.Rmd + presentation.html: Your presentation slides README.md: Your write-up /data/*: Your dataset in csv or RDS format, in the /data folder. /proposal: Your proposal from earlier in the semester Style and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formated. If you work in the same repository as your teammate, so merge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck. Review the marking guidelines below and ask questions if any of the expectations are unclear. Code: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented. Exception: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion. Marking Write-up 15 pts Reproducibility and organization 10 pts Team peer evaluation 10 pts Classmates’ evaluation 5 pts Criteria Content - What is the quality of research and/or policy question and relevancy of data to those questions? Correctness - Are statistical procedures carried out and explained correctly? Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations? Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? "],["ch-invitation.html", "Chapter 5 Invitation to Data Visualization 5.1 Atmospheric carbon dioxide concentration 5.2 Human health and development 5.3 Weather 5.4 Journalism 5.5 Historically important visualizations 5.6 Stories 5.7 Futher reading", " Chapter 5 Invitation to Data Visualization In this lesson I will provide some examples of interesting and influential data visualizations. In the task for this lesson, I will ask you to identify two visualizations you find interesting and provide a brief description and analysis of each. 5.1 Atmospheric carbon dioxide concentration Climate change in the recent past and coming century will be controled by human-driven emission (and possibly sequestration) of carbon dioxide from fossil fuels into the atmosphere. Starting in the 1950s, the amount of carbon dioxide in the atmosphere (in parts per million) was regularly measured. Subsequently, methods for analyzing gasses trapped in ice were used to extend this record back about one million years. There is a direct physical link between atmospheric concentration of carbon dioxide and the loss of heat from Earth to space, resulting in a mechanistic link between increasing carbon dioxide concentration in the atmosphere and the mean temperature of the surface of the Earth. Visualizations of this data and assocated global mean temperature data have been extremely influential, forming the cornerstone of books, a documentary movie, and countless educational and environmental change movements. Figure 5.1: Two years of atmospheric CO\\(_2\\) concentration from Mauna Loa observatory. Source co2.earth and sioweb.ucsd.edu Figure 5.2: Atmospheric CO\\(_2\\) concentration from Mauna Loa observatory, 1958 to present. Source co2.earth and sioweb.ucsd.edu Sample visualizations of atmospheric carbon dioxide are available from the institute that has been collecting this data for decades. Estimates of global mean temperature over time are available from NASA. Many other sites have information on these data, usually presenting data visually as a testament to the importance of visualizations. 5.2 Human health and development Hans Rosling was a physician and popularizer of data visualizations to develop understanding of human health and economic development over time and across countries. His public presentations illustrate his view of how dyanmic charts can help us come to see the trajectory of global development, particularly the connections between health and economic development. I strongly encourage you to watch his presentations. He was especially well known for his effort to dispell misunderstandings about differences across countries in health and human development. He popularized a style of scatterplot which combined the use of colour, symbol size, and animations to show changes over time. Figure 5.3: Fertility rate (babies per woman) as a function of median national income across countries. See the animated version showing how this relationship has changed over time. Source gapminder.org 5.3 Weather Many people are strongly interested in their local weather conditions. As a result of this strong interest and the complextity of the data, many visualizations have been developed. Forecasts, such as those produced by Environment Canada, and historical retrospectives, such as those produced by Weatherspark are examples that leverage familiarity with the data, broad-scale human interest, and data-rich but not overly complicated displays. Two examples are shown below. Figure 5.4: Environment Canada weather forecast for Halifax NS, December 10, 2020 Figure 5.5: Climatological mean daily high and low temperatures in Halifax NS from weatherspark.com 5.4 Journalism In the past decade there has been a resurgence of interest in data visualizations, stimulated in part by journalists emphasising visualizations in their publications. This example in the New York Times shows projected earnings for college graduates in a range of fields of study and is accompanied by notes and discussion questions. The New York Times has a series of educational materials on both visualizations and their stories. 5.5 Historically important visualizations Many ideas in contemporary data visulizations can be traced back to the 19th century, as represented by several impactful examples. In 1869, Charles Minard produced a map of Napoleon’s Russian campaign of 1812. Florence Nightingale was a pioneer user of data visualizations to communicate messages about sanitation and public health, famously in a polar histogram showing causes of mortality of soldiers. Also in public health, John Snow mapped a cholera outbreak in London, visually linking deaths to a water source. All of these visualizations were great advances over the bills of mortality produced a few centuries earlier. 5.6 Stories A common observation is that humans learn from stories. What is the role of data and its visualization in story telling? A graph does not tell a story by itself, but a story can be weaved from a combination of words and some data visulizations. Wilke’s book has an excellent argument in favour of storytelling with data which he tells in a video (starting at time 6:42). His essential elements of a story are an arc including an opening, challenge, action, and resolution, which results in an emotional reaction such as excitement, curiosity or surprise. The principle is that the emotional response from the resolution of the challenge gets your audience engaged and helps them retain your message. It may seem that a graph is far removed from a story. A pair of graphs, or a dynamic graph, or even just an original graph and an updated graph can be used to tell a story. For example, return to the carbon dioxide figures at the top of this section. Two years of data show a seasonal cycle in atmospheric carbon dioxide with a modest year over year trend. Suppose that was all you knew about carbon dioxide. It would be hard to know why there was a problem. Now look at the record since 1958. It’s now clear that there is a long-term increase and the interannual variation is small in comparion. If you find the 800,000 year record from ice cores, you will see even more context – current atmospheric carbon dioxide concentrations are outside the range of documented variability for the past 800k years. We will return to the theme of story telling frequently in the course, particularly in assignments. 5.7 Futher reading Kurt Vonnegut summary of story arcs Wilke, Fundamentals of Data Visualization Chapter 29 "],["ch-tools.html", "Chapter 6 Computer tools 6.1 R 6.2 Rstudio 6.3 Grammar of graphics (ggplot2) 6.4 tidyverse 6.5 R Markdown 6.6 Git and Github 6.7 Further reading 6.8 Resources", " Chapter 6 Computer tools We will use R and Rstudio in this course. R is widely used to analyze data and comes with many add-on packages for statistical analysis, data visualization, and specialized tools for many disciplines and applications. We will just scratch the surface of what R can do, but by the end of the course you should feel comfortable learning to use R for data visulization and you will have the skills to learn how to use R for many other tasks. Rstudio is a graphical user interface for R with many convenient features including tools to support report writing, getting help, and project management. For data visualization we will use ‘ggplot2’, for data analysis we will use the ‘tidyverse’ style of programming, for report writing we will use ‘R markdown’, and for project management we will use R projects and ‘git’ version control. All of these computer terms will mean much more to you later on in the course! In this lesson I will explain why we use each of these tools and the main features that make each useful. Your task for this lesson is to get your computer set up with the necessary software so that you are ready for the rest of the course. 6.1 R R is open-source software developed by a core team of programmers, which is made available for free to all users along with the full ‘source code’ for the software so that any one can find out exactly how any part of the software works. R was first developed in the mid-1990s and is now a quite mature language, although development continues. For example a brand new notation was just introduced in December 2020. R was developed after a couple decades of experience with its predecessor S and a commercial product known as S+. R has many strengths that account for its popularity and longevity. It is a very flexible and expressive language, which allows for many styles of programming and the use of both powerful tools to perform sophisticated analyses easily and also the flexibility to develop your own computational tools from basic computations. There is a huge, global community of users who continually develop new tools for R and make them available and easy to install on your computer. This means that anyone can develop a new data analysis method and readily distribute it on a widely-used platform to anyone comparatively easily. This is tremendously powerful! A third key ingredient is a very helpful community of users who develop tutorials and books to help newcomers to R learn to use it. Our course will use three such books, which can be purchased, but are also available for free on the internet. On the other hand, R is a challenging tool to learn. To accomplish any task you must type instructions into the computer. This can be daunting as you must first learn what instructions are available, what they do, and how to use them. If you have had experience with programming before (for example using Python or Java) you will know that there are many ways to go wrong and the computer’s output is not always easy to understand, especially when things go wrong! Nevertheless, the R style of computing with data, once you have been initiated, allows for endless possibilities in terms of data analysis. Our approach in this course will be to demonstrate a few sample calculations and computing tasks in each lesson and encourage you to become proficient in these tasks through repetition and minor modifications. Over time, you will come to understand both how to use the tools to analyze and visualize data and how to interact with R to accomplish new tasks. 6.2 Rstudio Rstudio is a graphical ‘front end’ (or integrated development environment) to the R software. It provides an editor for documents, a convenient way to see plots, get help, explore data objects created with R, manage report writing, and sets of files used collectively as part of projects. As with R, you will find that Rstudio has many features that will take you a while to discover. In this course we will focus on a few features and leave you to find others on your own. 6.3 Grammar of graphics (ggplot2) Since this is a course in data visualization, creating plots from data is a core skill. To get a computer to make a graph, you need to bring data together with instructions for producing the graph. Traditional ways to make graphs have been idiosyncratic, with each kind of graph having its own specialized instructions, even for features common to many plots such as the use of size adjustments, symbols, or colors to represent numerical or categorical scales. The ‘ggplot’ style arose out of a recognition that having a language (or ‘grammar’) to describe graphical displays of data was superior to other styles of graphics creation. (The gg in ggplot is an abbreviation for the grammar of graphics.) A common language is used to connect variables in your dataset to aesthetic features in your plot, such as position along an axis, symbol size, shape, or colour. This association is separate from selecting how the data are to be represented (e.g., as points, a line, a histogram). Another key element is how ranges of values are associated to sizes, shapes, and colours; these are called scales and they too have their own functions, which work regardless of the type of plot being made. Finally, annotations such as axis labels, and formatting of other elements (e.g., fonts, sizes, positions of non-data elements) may be adjusted to customize a plot. Essentially ggplot provides a tool for making graphs which is modular, and thus allows you to quickly and efficiently learn to make new kinds of plots and modify them. The proof that this works is that since ggplot2 was first developed, many users of the software have contributed their own styles of plotting which can be incorporated into the design of the original software. All this makes plotting data sound complicated, but in fact making a simple plot with few customizations is actually very easy once you get the idea behind the grammar of graphics. 6.4 tidyverse The starting point for each visualization we will produce and each analysis we will do is data. The developers of the tidyverse set of tools in R noticed that we all do many of the same kinds of operations to our data. A few style suggestions about how to organize your data and how to analyze data can provide both great flexibility and simplify common tasks. There is nothing that can be done in the tidyverse style that I couldn’t figure out how to do before these tools were developed, but the R code I write now is much easier for me and others to read. The problem solving process I use is much more streamlined than it used to be since I tend to use the same kinds of solutions for each new dataset I examine. There are two central ideas in the tidyverse approach to data analysis. (1) Data should be arranged in rectangles (or two dimensional arrays) with variables in columns and observations in rows. (2) A data analysis calculation should be broken down into a series of simple, modular functions that are composed together, such as filtering rows, grouping rows together, and computing summaries. Essentially this forms a grammar of data analysis, analogous to what ggplot did for plotting graphics. 6.5 R Markdown Once you know how to produce a data visualization or statistical analysis, new challenges quickly arrive. You must communicate these results to someone else. You must be prepared to revise your analysis and repeat it on revised or new data. A common approach is write lots of little bits of computer code, cut and paste the results into a word processor, and try to remember how it all fits together. R markdown documents are key step in a better solution. An R markdown document contains both natural-langauge (e.g., English) text for humans to read and R code for the computer to use. The R markdown document can be compiled (we will say ‘knitted’) together with the results of R computations to provide a finished report. This enables the computer code and data analysis results to be kept together with the exposition about the data and results. 6.6 Git and Github Git is distributed version control software. This means that it is a tool to help you keep track of versions of computer code, including R markdown documents, both in your own files and however you choose to share them with others. It has tools for managing versions of software in databases called repositories. Version history and management is useful if you revise a report you have prepared but want to keep access to the old style of report for archival purposes. Having access to old versions of data visualizations is essential for auditing and quality control as well. Git also enables two or more people working in different locations to collaborate on the same project, managing changes that are logically independent but made between file exchanges and helping collaborators resolve conflicts in edits. Git is widely used in the data science world and among software developers. We will be learning the most basic uses of git in our course. Github is a web service that allows you to easily publish your git repositories. Rstudio has easy to use tools for managing your work using git and github. These course notes are written and published using Rstudio, git, and github. You will use the same tools for your assignments and term project. 6.7 Further reading Healy Sections 2.1-2.4 contains excellent advice on the reasons for using R markdown, R/Rstudio, projects, the basics of R, and being patient as you learn computing tasks. We will return to the basics of R at various points in the course. Wilke has a thoughtful perspecitive on the ever changing landscape of software for data analysis. The tools we use will change, but we need to learn to make visualizations today, so we consider both the why and the how of data visualizations. Wilke emphasizes the why, but he has been strongly influenced by the tools we are using. I’ve been drawing computer graphics for over 30 years and used countless tools and ideas. The methods in this course are the best I’ve ever used; ggplot and the tidyverse constrain my work in just the right way to make it better. R4DS Chapters 26 and 27 contain a valuable introduction to R markdown and its use for commuication. 6.8 Resources If you want to know a lot more about using Rstudio, here is an hour-long video overview of Rstudio features If you want to know more than we will cover about git and github, see the notes called Happy git with R. All the essentials of using these tools will be explained in future lessons. R Markdown for scientists Some R Markdown tips "],["setup.html", "Chapter 7 Setting up your computer 7.1 R 7.2 Rstudio 7.3 Git 7.4 rstudio.cloud 7.5 Dalhousie on-campus labs 7.6 Packages 7.7 Github", " Chapter 7 Setting up your computer The statistical software R and RStudio and version control software git will be used in this course. No prior experience with R, RStudio or git is assumed. We’ll take class time to learn the software. In this lesson you will install the software on your computer, learn to use the software “in the cloud”, create a github account, and complete a task to let me know this is done or ask for help and tell me your github account name. The steps below are demonstrated for a Windows and Macintosh computer in videos on Brightspace. available on Brightspace. If you use a Chromebook, you can’t install this software, so skip ahead to the rstudio.cloud section. If you use linux, follow the instructions below to install the software and contact me if you have trouble. 7.1 R To download and install R go to r-project.org and click on the link to download R 7.2 Rstudio To download and install Rstudio, go to Rstudio.com and click on the link to download Rstudio 7.3 Git To download and install git: on Windows, go to git-scm.org and click on the link to download a version for Windows on Macintosh, use the Terminal app and type ‘xcode-select –install’ to download and install git. 7.4 rstudio.cloud If you have a Chromebook you can use R, Rstudio and git through the cloud service rstudio.cloud. Everyone should learn to use the cloud service as a backup in case of problems with the software on their own computer. 7.5 Dalhousie on-campus labs R and Rstudio are available on Dalhousie computer labs, but the git version control software must be installed following the instructions for Windows computers above. Since all your user files are erased from lab computers when you log out, this process must be repeated on each login. 7.6 Packages You are not done downloading and installing software yet! Most of the tools we will use with R are distributed as add-on packages. These are bundles of software that add new functions to R. There are three steps to use a pacakge: Install the package (done only once) Tell R you will be using the package (done each time you start R) Learn how to use the package (a major goal of this course) I install new packages all the time on my machine. Right now I have 203 installed. It’s also common to update to new versions. Rstudio trys to help you identify packages you need to install – we’ll see how later on. An optional task for today is to install packages suggested by Healy in his Preface. (We’ll use lots more packages than this, but this is a good start.) Cut and paste the following R code into the window marked “Console” in Rstudio. my_packages &lt;- c(&quot;tidyverse&quot;, &quot;broom&quot;, &quot;coefplot&quot;, &quot;cowplot&quot;, &quot;gapminder&quot;, &quot;GGally&quot;, &quot;ggrepel&quot;, &quot;ggridges&quot;, &quot;gridExtra&quot;, &quot;here&quot;, &quot;interplot&quot;, &quot;margins&quot;, &quot;maps&quot;, &quot;mapproj&quot;, &quot;mapdata&quot;, &quot;MASS&quot;, &quot;quantreg&quot;, &quot;rlang&quot;, &quot;scales&quot;, &quot;survey&quot;, &quot;srvyr&quot;, &quot;viridis&quot;, &quot;viridisLite&quot;, &quot;devtools&quot;) install.packages(my_packages) 7.7 Github Github is a web service for sharing and publishing github repositories and many related services. For today, all you need to do is create an account and tell me your github name on a Brightspace quiz. Once I have your github name I will send you an invitation to join course resources by email. "],["look-data.html", "Chapter 8 Look at Data 8.1 Problems with numerical summaries 8.2 Good and bad figures 8.3 Perception guidelines and cautions 8.4 Decoding graphs 8.5 Where to put 0? 8.6 Lines, shapes, or connect the dots? 8.7 Thinking about your goals 8.8 Further reading", " Chapter 8 Look at Data We’re learning to make data visualizations, so naturally we want to make good ones. What makes one visualization good and another bad? Are there specific qualities to emulate or avoid? How can we meaningfully discuss visualization quality without emphasizing personal preferences and taste? Healy Chapter 1 has many good answers to these questions, while recognizing that the subject is somewhat subjective. In this lesson we will try to develop some tentative answers to the following questions: What can you learn more easily from a visualization than from a table of data? What makes a good visualization? What features of human visual perception should be considered when designing data visualizations? There is much more in Healy Chapter 1 than the highlights in this lesson. I suggest you read the chapter carefully and return to it several times throughout the course. 8.1 Problems with numerical summaries Numerical summaries of data (e.g., mean, median, quantiles, standard deviation) are very useful but sometimes conceal more than they reveal. Discussions of financial aspects of life in the news – whether incomes, taxes, or assets often suffer from these problems because distributions of the underlying data are skewed. Similarly, numerical summaries of relationships between two or more variables (e.g., correlation, linear regression parameters) can be misleading in the presence of outliers (see Healy Figure 1.2, 1.3) or unexplored features of the relationship. The main problem with these numerical summaries is the distillation of a complex data set to a very small set of numbers. Visualizing data allows many more data to be represented and exploits the human visual system to interpret the relationships, without any statistical pre-filtering (e.g., by selecting an average or a linear model). Two synthesized datasets illustrate these phenomena through extreme cases: Anscombe’s Quartet and the Datasaurus Dozen. The data on each panel have the same numerical summaries (mean, standard deviation, and correlation), yet the underlying patterns are clearly very different. These problems are generally resolved by the rule: always plot your data; don’t rely only on numerical and statistical analysis. 8.2 Good and bad figures What makes a visualization good? Or bad? We’ll explore some answers, but the simplest test is this Is the main impression a viewer gets the one you intended as a designer? Is the interpretation faithful to the underlying data? To answer these questions, you need to do some work after you’ve made the visualization. You need to continue to probe the data to be sure you are not misrepresenting the data. You need to use the visualization for communication and find out if your audience understood your message, or if they got some other impression as a result of the visualization choices you made. 8.2.1 Chart junk Sometimes to dress up a display of data, designers will add graphic elements which are not determined by the data, but are instead designed to guide your interpretation of the display. These elements are not part of the visualizations we will create – they are elements of infographics or advertising to persuade and illustrate rather than display data. We are focused on displaying data. (For examples of bad infographics, just search knitr::include_graphics(&quot;static/cbc-2019-oct-21-election.jpg&quot;) Figure 8.1: Still from CBC Canadian Federal election coverage, October 21, 2019. Does the three-dimensional bar chart help you understand the election outcome? Are the bars the right height? Is it helpful to have the bar chart appear in the middle of the studio set? Can you judge the height of the bars? 8.2.2 Distracting colours, images or shapes Good visualizations don’t have to be minimalist black and white, but the use of colour, shape and other elements should be chosen deliberately to enhance the message told by the data. Colour can be used to highlight contrasts or create groups. Shapes are harder to distinguish, especially if there are many parts. Healy examined many of these perceptual aspects of plots in Sections 1.4 and 1.5. 8.2.3 Bad data Data can be wrong in many ways, but even if the data underlying a figure are correct, you must be sure that the message conveyed by the data matches the presentation of the figure. A survey of how people spend their time reported in Our World In Data is typical – does the plot really tell you what it looks like at first glance? Or is it more about age distributions, gender roles, and other sociological factors than the experience of a “typical person” in each country? If it’s too hard to tell, the visualization doesn’t work. Figure 8.2: Source: OECD time use database, Our World in Data and tweet by @simongerman600 on 2020-12-13. 8.3 Perception guidelines and cautions Many features of a visualization can make it harder to interpret than you, as a designer, intend. Once you know the message of a graph, it may be difficult to see problems with visualizations you create, since you know the intended message. So you must keep an eye out for unintended messages and difficult to decode graphs. Stacked bar charts (Healy Figure 1.11) make some comparisons across groups difficult because the baseline of one colour does not line up to the corresponding region from one bar to the next. The aspect ratio (Healy Figure 1.12) can make a small change look large, and the reverse by exploiting our perceptions. The checkerboard illusion (Healy Figure 1.14) is an example of how our brains process brightness in the context of neighbouring parts of the image. The squares labeled A and B are the same colour, represented by the same underlying data, but look completely different. Colour or grayscale brightness, as a result, is not a good way to indicate a quantity to be compared across regions of a plot. (By contrast, a small number of colours can be very effective at distinguishing a small number of categories.) knitr::include_graphics(&quot;static/checker-shadow-illusion.png&quot;) Figure 8.3: The checker shadow illusion. Wikipedia 8.4 Decoding graphs Data are generally described as quantitative or categorical. Each type of data has its own suite of representations and challenges with perception. For quantitative data, the most direct representation is the position of a symbol on a line, like the ‘number line’ of elementary school math classes. Other comparisons such as the lengths of a line, slopes of a line or angles in a pie chart, colour brightness and saturation, and area or volume are more difficult to make quantiative (roughly in that order from easiest to hardest). These orderings are reasonably intuitive, once explained, but are also supported by quantitative experimental data (Healy Figures 1.22-1.24). The options for categorical data are somewhat simpler: position is still useful, then colour hue, and shape (Figure 1.25). The number of categories should be kept small, particularly for colour and shape, or your message will likely be lost in the detail of the visualization. 8.5 Where to put 0? A common rule for quantitative displays using position is that you should always include 0 on your axis. The reason is simple, we often want to make comparisons of absolute differences and relative differences. Ratios of two quantities read from distances will only be sensible if the distance from 0 can be seen. Rules which are absolute and always true are rare. For the data shown below, which visualization is better? What if dots were used on the left and bars on the right? Figure 8.4: A bar chart and dot chart version of the same data. The extent of the horizontal axis differs on the two panels. 8.6 Lines, shapes, or connect the dots? A common question when plotting a scatter plot of two quantitative variables is whether to use lines, points, or both for the data (see the sketch below.) Which is appropriate? Often data points are discrete and little is known about values between the points; lines can thus be misleading because they give a visual indication of data between points. Lines act as guides joining points with the same symbol, which gives a stronger visual impression and can simplify the message of a complex plot. If the underlying data are continuous and the lines are a reasonable representation of the process being represented, then symbols may be unnecessary. In short, the most appropriate representation depends on your understanding of the data and the message to be communicated. knitr::include_graphics(&quot;static/points-lines.png&quot;) Figure 8.5: Points or lines? 8.7 Thinking about your goals Almost all decisions about data visualizations come down to this: what is the best choice to highlight the most important feature of the dataset? How will your reader interpret your visualization? Does your picture represent the data fairly? Are there perceptual problems that make the picture easy to misinterpret or difficult to understand? 8.8 Further reading Both these chapters are strongly recommended. These notes are just a brief introduction. Healy Chapter 1 Wilke Chapter 1 emphasizes the difference between ugly, bad, and wrong figures, echoing many of the observations made here. The rest of his book addresses these questions in considerable detail from the perspective of someone training students in good and bad features of graphics, focusing on many of the same perceptual issues introduced here. "],["first-plot.html", "Chapter 9 Making your first plot 9.1 Required elements for a plot 9.2 Your first plot 9.3 Improving your plot 9.4 Exercises 9.5 Further reading", " Chapter 9 Making your first plot In this lesson you will start to learn how to use ggplot to visualize data. There is one simple example with several exercises, designed to make the essentials clear in your mind. All plots share the three features explained below, but many plots we draw later in the course are much more complex. You can read these notes as a static document in a web browser, but it’s better to download the R markdown file here, open it in Rstudio, and edit the examples as you read. 9.1 Required elements for a plot You need three elements to make a plot using ggplot: data, in the form of tidy data (a data frame or tibble in the language of R) a mapping from variables in the data to features on the graph (e.g., position on the x- or y-axis, colour, shape, size) the kind of graph to draw, such as a scatter plot, histogram, or bar chart. 9.2 Your first plot We will use the gapminder data, which must be installed as part of the gapminder package and is adapted from the data at gapminder.org. The function to create a plot is ggplot. You must specify the data (gapminder) and the mapping between various columns of the data and the features of the graph. Once these basics are established, we add (+) one thing to the graph: an instruction to place a symbol at each x, y combination using the “geometry” geom_point. We’ll have a lot more to say about how data are organized in tables later, but for now you can look at the data by typing View(gapminder) in the Rstudio Console. library(gapminder) library(ggplot2) ggplot(data = gapminder, mapping = aes(y=lifeExp, x=gdpPercap)) + geom_point() 9.3 Improving your plot We’re going to revise the plot by building on these instructions. I’ll repeat the instructions above, but instead of displaying the figure, I will store the result in a variable (conventionally called p for plot to keep it simple, but you can use any name you like.) This will simplify the examples to follow, highlighting what makes each example different. p &lt;- ggplot(data = gapminder, mapping = aes(y=lifeExp, x=gdpPercap)) + geom_point() Add better labels to your plot using labs and x, y, title, subtitle, tag. My example has placeholder text. Get the R markdown file from here and revise the figure to show sensible text in these spaces. p + labs(title=&quot;Title here&quot;, subtitle=&quot;A subtitle&quot;, x=&quot;x axis label&quot;, y=&quot;y axis label&quot;, caption=&quot;A caption.&quot;, tag=&quot;A.&quot;) Almost everyone makes the text on their figures too small. How small is too small is obviously a matter of judgement, but it depends on your age (and vision), the medium (on screen for yourself, on a website, in a presentation, printed on paper), and whether the figure is made by you for you, or if you are trying to reach a wider audience. It’s essential to know how to make text bigger! Many visual aspects of a ggplot can be controlled as part of the theme; we will introduce these gradually throughout the course and summarize some of the most important themes in a lesson near the end of the course. p + theme(text = element_text(size=18)) Let’s make a simple use of colour. There are many countries, so that’s not a good choice for a colour feature – there will be too many to distinguish. Let’s colour points by continent. All we need to do is to link the variable continent to the colour aesthetic. p + geom_point(aes(color=continent)) Gross domestic product varies widely across countries. The uneven spread over the x-axis makes the visualization hard to read. It’s got a couple of other features, notably the fact that it is always bigger than 0 and that we tend to be interested in multiplicative comparisons, that mean a log-transformation makes a better plot. (This is debatable if you are not used to reading or noticing log scales. Log scales are very useful and well worth the trouble to learn about, so put that on your “to do list” if you haven’t learned how to read them yet.) ggplot makes changing the scale farily easily, at least for a few special cases. The stuff in brackets after scale_x_log10 is optional and makes the labels look a bit prettier. (Notice we’re using a function from a new package here.) library(scales) p + scale_x_log10(labels = trans_format(&#39;log10&#39;, math_format(10^.x))) This formatting of the numbers on the x-axis is a bit tricky to get right and to explain. In fact its the sort of thing you might keep in a file of examples if, like me, you really don’t like to see \\(10^3\\) formatted as \\(1.0e3\\). (Try labels = scientific to see this other format.) 9.4 Exercises Combine several features of the examples above into one example: colour, log scale on the x axis, better axis labels and titles, and of course changing the text size. Repeat these examples using variables of your choice from the penguins data from the package palmerpenguins 9.5 Further reading Healy Section 2.5-2.6 For more on aesthetics and mappings from data to visualizations, see Wilke Chapter 2 "],["vcs.html", "Chapter 10 What is version control software? 10.1 What software is used for version control? 10.2 Why is version control used in data visualization? 10.3 How will we use version control? 10.4 Introduction to git 10.5 Using git with Rstudio 10.6 Setup 10.7 Practice tasks 10.8 Clean up 10.9 Your first assignment from github 10.10 Resources", " Chapter 10 What is version control software? Version control software is used to manage the process of creating software. It is commonly used to track changes, manage the revision process of correcting errors and adding new features, tracking the history of a project through different versions, synchronizing contributions from many different people, and faciliating the distribution to a broad audience. Version control software is most commonly applied to the production of complex projects like software, but it can be used for text documents, data, and many other applications. 10.1 What software is used for version control? Version control software has a history dating back several decades, so there are many different tools available. We will be using one of the most popular packages, known as git (Wikipedia, homepage). Git keeps the entire history of a project on your own computer and does not require any central repository. Since version control software is often used to coordinate the work of many authors and to distribute the product, central repositories such as GitHub (Wikipedia, homepage) have become very popular, to the point that some people see them as an integrated set of tools. Other popular version control software packages include Mercurial and Subversion and central repositories such as bitbucket and more. We will be using git and github in this book. 10.2 Why is version control used in data visualization? Data visualization is the process of combining data with computer code to create a visualization. Both of these parts can change with new information and new ideas, can require synthesis of skills from multiple authors, and benefit from transparency in design and distribution. As a result, version control software is a natural tool to help with the work of data visualization. Suppose you develop a data visualization and you want to distribute the result, but you anticipate updating the data and revising the analyses. This sequence of steps is very similar to software development: an initial version is produced and released to users, changes are made, new versions are produced. Users (of software and data visulizations) want to know what version they are using, if there are any updates, and what the changes were between the versions. Version control software can help with these tasks and, once the key concepts are understood, without much extra effort on the part of the team producing the data visualization. Understanding this workflow is a valuable technical skill on its own. In this course we will integrate just enough use of version control to help you see how it can be helpful and to get you past the uncomfortable stage of knowing what version control is without knowing the basics of how to use it. You will be fluent beginner users of the git model of version control by the end of the course. 10.3 How will we use version control? Most evaluations in our course will require you to use git and github. Depending on how you work on your final project, you may use it as a tool for collaboration. This course will emphasize the most basic uses of git and give you an opportunity to practice core elements of using git. 10.4 Introduction to git Git organizes data in a repository, commonly called a repo. The repo contains a copy of all the files you ask git to track and it tracks all changes you make to the files. One you create a repository you must stage or add files to the repository. Staging is a declaration that the current version of a file is the one you want to added to the repository. Each file must be staged as a separate step. (In Rstudio this just means checking a box.) Once you have staged all the files you want, you commit them to the repository. This updates the repository, moving files from the staged area. New files are stored in their entirety. If a file has been changed, only the differences between the old and new versions are retained. All of these changes happen on your own computer, in a subfolder called .git used by git to keep track of the repository. If you are using a service like github you can then push your changes to the remote location so that they can easily be obtained by others. 10.5 Using git with Rstudio Here are the most important steps for using git with Rstudio. It looks like a lot of steps, because I’ve broken down each task into simple steps. In practice, once you are used to the process, it’s all quite simple. I’ve prepared a video walkthrough (Brightspace, link to come) of each step that you can follow along with. Check to be sure git is working on your computer Create a new Rstudio project in a new folder and enable version control Add a file to your project Stage your files to your local git repository Commit your staged changes to your local git repository Create a remote repository on github Tell Rstudio and git where to find this remote repository Push your changes to your github repository Revise a file in your project (including renaming, creating new files) Stage those changes Commit those changes Push the changes An important variation on this process in our course will arise with assignments. For assignments, I will create a repository for you on github containing instructions and possibly some data files. You will create a new Rstudio project on your computer based on this repository (known as cloning a repository). This takes care of a lot of the steps above: creating the repository, adding files, creating a github repository, and connecting your local repository to the remote location. Then you just focus on the main steps: staging, committing, and pushing. 10.6 Setup You should have already done this step as part of an earlier lesson. The instructions are repeated below in case you missed the step or something went wrong. 10.6.1 On rstudio.cloud Git is already installed on rstudio.cloud. There are several ways to confirm this. You can click on the “terminal” tab and type git. You will see a help message instead of an error message. Under the menu item Tools &gt; Version Control &gt; Project setup, you will see git as a choice in the popup menu for “version control system” instead of “none”. Using File &gt; New Project &gt; Version Control &gt; Git to create a new project using a remote repository (such as this sample) will work. 10.6.2 On a Macintosh (OSX) computer To install git, open “Terminal”, either within R or using the application Terminal found in the Applications &gt; Utilities folder, and type xcode-select –install and wait a few minutes. Type git at the terminal to check that the installation worked. 10.6.3 On a Windows computer Download git from git-scm using the download link. Run the installer, accepting all the default options in the many dialog boxes that appear. When you are done, type git in the Rstudio terminal. If you see some help text displayed instead of an error message you know git is installed. 10.6.4 Set up a github account Create a free account at github.com Tell me your github account name by filling in the brightspace survey for Task 1. In a day or less you will get an invitation by email to join the course on github. Accept the invitation. When you pull files from or push files to github you will need to enter your password. An authorization key can be place on your computer to let you skip this authentication step. (Instructions to come.) Do not move on to the next steps until you have git working properly on your computer. If you can’t get it working, use rstudio.cloud for now. 10.7 Practice tasks Here’s a step-by-step guide to creating a new Rstudio project in a new folder using git version control. 10.7.1 Create a project Start Rstudio. If you are already working on some other files, choose: Session &gt; New session Use the Rstudio menu: File &gt; New Project… &gt; New Directory &gt; New Project Give the directory for your new project and place in a deliberate place on your computer (e.g., on the Desktop, in a folder called STAT2430, or whatever you prefer.). Make sure “Create a git repository” is checked. Then click “Create Project”. 10.7.2 Create a new markdown file Use Rstudio menu: File &gt; New file &gt; R Markdown … Give the document a title and make sure your name appears in the space for Author. Use HTML output. A standard template for an R markdown file will be created. Save the file in your new project. Call it something like “example” or “testing”. If you like, click “knit” to see the output of the R markdown document. We’ll learn more about this later. 10.7.3 Stage and commit your changes Click the “Git” tab in the upper right of the Rstudio window. You should see three files – the Rmd file you just created plus “.gitignore” and and Rproj file that stores information about your project. Check the “Staged” box beside all three files. You have now told git you want to add these to your local repository when you next commit changes. Click “Commit”. A pop-up window will show you the files you are committing with changes (everything, since we’re making our first commit). You are asked for a “commit message” in the upper right. Type a short informative message here. This is a valuable record of what you were hoping to achieve with these changes. I’ll type “learning git and making my first commit to my first repository”. Click “Commit”. A message box appears showing you what happened. I don’t usually read this. Click “Close”. Close the Commit popup by using the “X” button to close a window on your computer. 10.7.4 Make some more changes to your files You should notice that the “status” display in the Git tab is now blank. There are no differences between the files in your R project and your local git repository. Let’s see what happens when we change this. Make a simple change to your Rmd file. For example, set the date to tomorrow. Save the file. Notice that the file now appears in your Git status tab. There should be a blue M beside the file name to indicate the file has been modified. Check the staged button. Commit the changes to your local repository. 10.7.5 Connect to github To publish these files on github you have to do a few steps. You need to create a repository on github. You need to connect your local repository to the github repository. You need to push the changes from your computer to the github (remote) repository. Repositories on github can be public (so anyone can see them) or private (so that only you and people you give explicit permission can see them.) We’ll make this repository private. Go to github.com. Click the bright green button “New” on the left next to the word “Repositories”. Give your repository a name. Don’t use spaces; use - or _ to connect words. I suggest “my_first_repository”. Click the radio button beside “Private” Don’t check any other boxes. Click the green button “Create repository” Copy the third last line of code on the next screen: git branch -M main. Go back to Rstudio. Paste the git command into the “Terminal” window and hit enter. Copy the second last line of code on the next screen. On my example its git remote add origin https://github.com/AndrewIrwin/my_first_repository.git. Your’s will have your github name and repository name. Paste it into the Terminal window. Do the same thing with the last line of code: git push -u origin main Go back to github and refresh your window. You should see your three files from your R project there in the web browser now. 10.7.6 Make and push another change You’re all done the setup now. Now we will practice the normal day-to-day work on an R project. Make a change to your Rmd file. Perhaps change the title or add your middle initial. Save the file. Stage and commit your changes to your local repository. Click the green up arrow in the Git tab to “push” your new changes to github. Reload the github window in your web browser. The start of your commit message should appear next to the files you changed. Congratulations! You are a git and github novice now. 10.8 Clean up If you don’t want to keep this repository, you can get rid of it in two steps. Delete the folder from your computer by dragging it to the trash (Finder on Macintosh, File explorer on Windows) Delete it from gitub. On the repository page on github.com, go to: Settings, then scroll to the bottom. From the “danger zone” choose “Delete this repository”. Github really doesn’t want you to do this by mistake, so it requires two confirmation steps. You must type the repository name to confirm and then enter your github password to confirm. 10.9 Your first assignment from github In the task for this lesson you’ll clone an exiting repository I created for you on github to create a new project on your computer (or rstudio.cloud account). This will be the first step for assignment 1. 10.10 Resources Rstudio help for git Happy Git with R Highlights of key features of git and github for developers Advanced Git cheat sheet A more advanced look at the internals of git "],["linear-models.html", "Chapter 11 Linear models 11.1 Making linear models 11.2 Adding linear models to visualizations", " Chapter 11 Linear models Linear regression is a powerful technique for finding a line that approximates a set of data. For the approximation to be a good one, the linear model must be appropriate for the data, which can sometimes be determined by reasoning about the processes that generate the data, and are sometimes justified based on statistical properties of the data. We will use linear models as a tool without elaboration of the methods or theoretical background; you should learn about those in a different statistical course. We will explore how to create a linear model, which can include a lot more than straight lines, and then discuss how to add those models to a visualization. 11.1 Making linear models We will always make linear models with variables from a data frame. Designate one variable the response variable, which we will attempt to predict using one or more other variables (called predictors.) You are not restricted to just variables in your data frame; you can transform the varaibles first, for example by squaring, taking logarithms, or applying some other function. Additionally, you can use categorical (or factor) variables as predictors and are not restricted to only quantitative variables. Be aware that the more variables or transformations you add to your list of predictors, the more likely they will be correlated and your model will be very hard to interpret. These issues are discussed in statistics courses on regression. Once your data frame is created, write the linear model as a “formula” object, meaning as an equation but with a ~ instead of an = to indicate that you are modelling the left hand side and allowing for a specific model for the mismatch between predictors and response. We have seen that the price of a diamond increases a bit faster than linearly as the mass of the diamond increases, we will try both a linear model and a quadratic model for data in the diamonds dataframe. linear_model1 &lt;- lm(price ~ carat, data = diamonds) summary(linear_model1) ## ## Call: ## lm(formula = price ~ carat, data = diamonds) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18585.3 -804.8 -18.9 537.4 12731.7 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2256.36 13.06 -172.8 &lt;2e-16 *** ## carat 7756.43 14.07 551.4 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1549 on 53938 degrees of freedom ## Multiple R-squared: 0.8493, Adjusted R-squared: 0.8493 ## F-statistic: 3.041e+05 on 1 and 53938 DF, p-value: &lt; 2.2e-16 quadratic_model1 &lt;- lm(price ~ carat + carat2, data = diamonds %&gt;% mutate(carat2 = carat^2)) summary(quadratic_model1) ## ## Call: ## lm(formula = price ~ carat + carat2, data = diamonds %&gt;% mutate(carat2 = carat^2)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26350.0 -724.2 -35.9 445.8 12881.1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1832.58 21.69 -84.5 &lt;2e-16 *** ## carat 6677.03 46.40 143.9 &lt;2e-16 *** ## carat2 507.91 20.82 24.4 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1540 on 53937 degrees of freedom ## Multiple R-squared: 0.851, Adjusted R-squared: 0.851 ## F-statistic: 1.54e+05 on 2 and 53937 DF, p-value: &lt; 2.2e-16 These results are the jumping off point for a lot more exploration. 11.2 Adding linear models to visualizations What we really want to do is to add a line to a graph. There are easy ways to do this with ggplot that don’t require you to make a separate model; instead we will just add a “smooth” geometry (geom_smooth) to a ggplot. We start with a straight line. diamonds %&gt;% filter(cut == &quot;Ideal&quot;, color == &quot;G&quot;) %&gt;% ggplot(aes(x=carat, y = price)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Now try a quadratic. diamonds %&gt;% filter(cut == &quot;Ideal&quot;, color == &quot;G&quot;) %&gt;% ggplot(aes(x=carat, y = price)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ poly(x,2)) That’s better, but it’s still not great. If we just want to highlight the pattern in the data, we can use a smooth that doesn’t work from a simple formula, such as loess or gam. diamonds %&gt;% filter(cut == &quot;Ideal&quot;, color == &quot;G&quot;) %&gt;% ggplot(aes(x=carat, y = price)) + geom_point() + geom_smooth(method = &quot;loess&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; This smooth has an “S” shape – price increases slowly for the smallest diamonds, then quickly, then slowly again for the largest diamonds. We get a similar result from a gam smooth. diamonds %&gt;% filter(cut == &quot;Ideal&quot;, color == &quot;G&quot;) %&gt;% ggplot(aes(x=carat, y = price)) + geom_point() + geom_smooth(method = &quot;gam&quot;) ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; The geom_smooth is especially powerful for facetted plots. The smooth is automatically computed and plotted for each facet separately. diamonds %&gt;% filter(color %in% c(&quot;D&quot;, &quot;F&quot;, &quot;H&quot;, &quot;J&quot;), clarity %in% c(&quot;SI1&quot;, &quot;VS1&quot;, &quot;IF&quot;)) %&gt;% ggplot(aes(x=carat, y=price)) + geom_point(aes(color=cut)) + facet_grid(color ~ clarity) + scale_colour_viridis_d(begin=0, end =0.8) + geom_smooth(color = &quot;black&quot;, size=0.75) # uses loess ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; # geom_smooth(method = &quot;lm&quot;, formula = y ~ poly(x,2), color = &quot;black&quot;, size = 0.5) # alternate version Notice that I’ve moved the color=cut from the ggplot function to the geom_point function as the aesthetic for only the points. If the colour was specified in the first ggplot function, the geom_smooth would “inherit” this aesthetic mapping and would make a separate smooth for each cut (5 lines per panel). There are not enough data in some panels for some cuts to do a good job, so I revised the plot to only draw one smooth per facet. You should move the color=cut back to the ggplot call to see how the result changes. "],["accessibility-bias-and-ethics.html", "Chapter 12 Accessibility, Bias, and Ethics 12.1 Accessibility 12.2 Data collection and analysis 12.3 Further reading", " Chapter 12 Accessibility, Bias, and Ethics Data visualization is about representing, including selecting, simplifying and organizing, data. It’s an activity done by humans, for questions generated and presented to humans, even if the underlying topic is about the natural world. As as a result, it is always important to think carefully about the human element. What steps can be taken to make our work accessible to as many people as possible? How may bias or discrimination enter into data collection, selection, analysis and interpretation? What are the ethical considerations to be considered in our work with data and the process of researh? This course only touches on these topics long enough to alert you to their importance. 12.1 Accessibility Data visualization is, as the name implies, the act of producing a product to be seen. This is a useful goal because our brains are very good at processing some kinds of visual information. Training to read visualizations can greatly increase the ability to extract information from a visualization, so it is important to know your audience – students, the general public, people with well developed quantiative skills, or domain experts for the data you are presenting. All of these factors are central to knowing if a visualization is suitable and effective. Our target audience is university students. Not everyone has the same visual abilities. Some people have vision that differs from the most common experience in some way – perceiving colours differently, reduced acuity, and other differences all the way to complete blindness. We should always keep these differences in mind when producing visualizations. To take the hardest challenge head on, what is the value in producing a visualization for someone who cannot see it? Data visualization is a process that uses the creator’s visual and technical skills to present features of a dataset. Any data visualization should be accompanied by a written description of the message to be conveyed. Ideally the visual and written aspects will complement each other. A visualization does not “say” anything by itself; a written interpretation is an essential part of the process. 12.2 Data collection and analysis Data collection and analysis are critical tools for understanding and interacting with the world. Data are used by academic researchers, goverments, corportations, non-profit organizations, and citizens in complex and contrasting ways. All of these processes create opportunities for bias and discrimination. The links below give a few examples and stories elaborating these challenges. Data encodes systematic racism from the MIT technology review, December 2020. Case studies in data ethics from O’Reilly publishers. Data and the COVID pandemic, opinion published in Patterns, July 2020. A business and marketing take on the ethics of data science A student’s perspective on ethics in data science from 2018. A professional statement on ethical data science from the Royal statistical society and the Institute and Faculty of Actuaries The following resources are in the form of checklists or questions to think about when collecting, analyzing, and presenting data. Data science ethics checklist 10 data science ethics questions If you find discussions of these topics you find particularly thought provoking or informative, please share them with me. 12.3 Further reading Data Science in a Box notes on ethics "]]
